---
author: "Samarth Bhargav and Anne Schuth and Claudia Hauff"
booktitle: "Proceedings of SIGIR'23"
date: "2023-04-25"
key: bhargav2023
doi: "10.1145/3539618.3592086"
pdf: /assets/bhargav2023.pdf
keywords: ""
layout: publication
title: "When the Music Stops: Tip-of-the-Tongue Retrieval for Music"
type: inproceedings
year: "2023"
shield: conference-SIGIR-blue
repo: https://github.com/spotify-research/tot
arxiv: "2305.14072"
---

We present the first study of Tip-of-the-tongue (ToT) retrieval for
music, where a searcher is trying to find an existing music entity,
but is unable to succeed as they cannot accurately recall important
identifying information. ToT information needs are characterized
by complexity, verbosity, uncertainty, and possible false memories.
We make four contributions. (1) We collect a dataset—ToT𝑀𝑢𝑠𝑖𝑐 —of
2,278 information needs and ground truth answers. (2) We introduce
a schema for these information needs and show that they often
involve multiple modalities encompassing several Music IR sub-
tasks such as lyric search, audio-based search, audio fingerprinting,
and text search. (3) We underscore the difficulty of this task by
benchmarking a standard text retrieval approach on this dataset.
(4) We investigate the efficacy of query reformulations generated
by a large language model ( LLM), and show that they are not as
effective as simply employing the entire information need as a
query–leaving a lot of open questions for future research.
